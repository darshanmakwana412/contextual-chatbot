{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "import os\n",
    "import rasa\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_dir, load_dataset_path, no_intents=None, entities=True):\n",
    "    with open(load_dataset_path, 'w') as yaml_file:\n",
    "        rasa_version = \"3.1\"\n",
    "        yaml_file.writelines(f\"version: {rasa_version}\")\n",
    "        yaml_file.write(\"\\n\\n\")\n",
    "        yaml_file.writelines(\"nlu:\\n\")\n",
    "        intents = os.listdir(dataset_dir)\n",
    "        for intent_file_name in intents:\n",
    "            intent_path = os.path.join(dataset_dir, intent_file_name)\n",
    "            intent_name = intent_file_name[:-5]\n",
    "            yaml_file.writelines(f\"- intent: {intent_name}\\n\")\n",
    "            yaml_file.writelines(\"  examples: |\\n\")\n",
    "            with open(intent_path) as json_file:\n",
    "                json_data = json.load(json_file)\n",
    "                intent_examples = json_data[intent_name]\n",
    "                if(no_intents==None):\n",
    "                    no_intents=len(intent_examples)\n",
    "                text_examples = []\n",
    "                intent_examples = random.sample(intent_examples, no_intents)\n",
    "                for data in intent_examples:\n",
    "                    texts = data[\"data\"]\n",
    "                    example = \"\"\n",
    "                    for text in texts:\n",
    "                        word = text[\"text\"]\n",
    "                        if entities:\n",
    "                            if \"entity\" in text.keys():\n",
    "                                entity = text[\"entity\"]\n",
    "                                word = f\"[{word}]({entity})\"\n",
    "                        example = example + word\n",
    "                    yaml_file.writelines(f\"    - {example}\\n\")\n",
    "            yaml_file.writelines(\"\\n\")\n",
    "            json_file.close()\n",
    "    yaml_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_dir = \"./dataset/Train/\"\n",
    "val_dataset_dir = \"./dataset/Validate/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data(train_dataset_dir, \"./model_data/train_20_data.yml\", no_intents=20, entities=True)\n",
    "load_data(train_dataset_dir, \"./model_data/train_100_data.yml\", no_intents=100, entities=True)\n",
    "load_data(train_dataset_dir, \"./model_data/train_200_data.yml\", no_intents=200, entities=True)\n",
    "\n",
    "load_data(val_dataset_dir, \"./model_data/val_data_entities.yml\", entities=True)\n",
    "load_data(val_dataset_dir, \"./model_data/val_data_no_entities.yml\", entities=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data(train_dataset_dir, \"./model_data/train_20_data.yml\", no_intents=20, entities=True)\n",
    "load_data(val_dataset_dir, \"./model_data/val_data_entities.yml\", entities=True)\n",
    "load_data(val_dataset_dir, \"./model_data/val_data_no_entities.yml\", entities=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\future\\standard_library\\__init__.py:65: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n"
     ]
    }
   ],
   "source": [
    "from rasa import model_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/gradients/cond_1/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_1_grad/gradients/cond_1/GatherV2_grad/Reshape:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/gradients/cond_1/GatherV2_grad/Cast:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\rasa\\utils\\tensorflow\\model_data.py:774: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.concatenate(np.array(f)),\n",
      "Epochs: 100%|██████████| 100/100 [02:34<00:00,  1.55s/it, t_loss=11, m_acc=0.185, i_acc=1, e_f1=0.839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Rasa model is trained and saved at 'models\\nlu-20221217-195337-jet-airport.tar.gz'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models\\\\nlu-20221217-195337-jet-airport.tar.gz'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rasa.model_training.train_nlu(\"./configs/diet-replace-mask.yml\", \"./model_data/train_20_data.yml\", \"./models/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFBertModel.\n",
      "\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at rasa/LaBSE.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "Epochs: 100%|██████████| 100/100 [04:23<00:00,  2.64s/it, t_loss=9.25, m_acc=0.655, i_acc=1, e_f1=0.905]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Rasa model is trained and saved at 'models\\nlu-20221217-201702-skinny-quail.tar.gz'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models\\\\nlu-20221217-201702-skinny-quail.tar.gz'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rasa.model_training.train_nlu(\"./configs/diet-heavy.yml\", \"./model_data/train_20_data.yml\", \"./models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mc:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\rasa\\shared\\utils\\io.py:98: UserWarning: The out of vocabulary token 'oov' was configured, but could not be found in any one of the NLU training examples. All unseen words will be ignored during prediction.\n",
      "  More info at https://rasa.com/docs/rasa/components#countvectorsfeaturizer\n",
      "\u001b[0mc:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Rasa model is trained and saved at 'models\\nlu-20221217-202735-hushed-atmosphere.tar.gz'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models\\\\nlu-20221217-202735-hushed-atmosphere.tar.gz'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rasa.model_training.train_nlu(\"./configs/config-origin.yml\", \"./model_data/train_20_data.yml\", \"./models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mc:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\rasa\\shared\\utils\\io.py:98: UserWarning: Entity entity 'facility' has only 1 training examples! The minimum is 2, because of this the training may fail.\n",
      "\u001b[0m\u001b[93mc:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\rasa\\shared\\utils\\io.py:98: UserWarning: You have defined training data consisting of entity examples, but your NLU configuration does not include an entity extractor trained on your training data. To extract non-pretrained entities, add one of MitieEntityExtractor, CRFEntityExtractor, DIETClassifier to your configuration.\n",
      "  More info at https://rasa.com/docs/rasa/components\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Rasa model is trained and saved at 'models\\nlu-20221217-202812-chilly-rectangle.tar.gz'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models\\\\nlu-20221217-202812-chilly-rectangle.tar.gz'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rasa.model_training.train_nlu(\"./configs/config-mega-basic.yml\", \"./model_data/train_20_data.yml\", \"./models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_grad/gradients/cond/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_grad/gradients/cond/GatherV2_grad/Reshape:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/cond_grad/gradients/cond/GatherV2_grad/Cast:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "Epochs:  34%|███▍      | 34/100 [02:56<05:42,  5.19s/it, t_loss=16.4, m_acc=0.327, i_acc=1, e_f1=0.669]\n",
      "Epochs: 100%|██████████| 20/20 [01:15<00:00,  3.79s/it, t_loss=9.71, i_acc=0.714, e_f1=0.831]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Rasa model is trained and saved at 'models\\nlu-20221217-200520-offline-chain.tar.gz'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models\\\\nlu-20221217-200520-offline-chain.tar.gz'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rasa.model_training.train_nlu(\"./configs/diet-light.yml\", \"./model_data/train_20_data.yml\", \"./models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 100/100 [03:28<00:00,  2.09s/it, t_loss=3.41, i_acc=1, e_f1=0.928]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Rasa model is trained and saved at 'models\\nlu-20221217-201213-isomorphic-extraction.tar.gz'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models\\\\nlu-20221217-201213-isomorphic-extraction.tar.gz'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rasa.model_training.train_nlu(\"./configs/diet-replace.yml\", \"./model_data/train_20_data.yml\", \"./models/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFBertModel.\n",
      "\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at rasa/LaBSE.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/gradients/cond_1/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_1_grad/gradients/cond_1/GatherV2_grad/Reshape:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/gradients/cond_1/GatherV2_grad/Cast:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-653' coro=<Agent.parse_message() done, defined at c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\rasa\\core\\agent.py:383> exception=KeyboardInterrupt()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\darsh\\AppData\\Local\\Temp\\ipykernel_12932\\3388937493.py\", line 6, in <module>\n",
      "    pred = get_prediction(query)\n",
      "  File \"C:\\Users\\darsh\\AppData\\Local\\Temp\\ipykernel_12932\\2737707585.py\", line 9, in get_prediction\n",
      "    pred = asyncio.run(nlu_agent.parse_message(message_data=query))\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\nest_asyncio.py\", line 35, in run\n",
      "    return loop.run_until_complete(task)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\nest_asyncio.py\", line 84, in run_until_complete\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\nest_asyncio.py\", line 120, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\users\\darsh\\appdata\\local\\programs\\python\\python38\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\nest_asyncio.py\", line 196, in step\n",
      "    step_orig(task, exc)\n",
      "  File \"c:\\users\\darsh\\appdata\\local\\programs\\python\\python38\\lib\\asyncio\\tasks.py\", line 280, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\rasa\\core\\agent.py\", line 409, in parse_message\n",
      "    return await self.processor.parse_message(message)  # type: ignore[union-attr]\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\rasa\\core\\processor.py\", line 640, in parse_message\n",
      "    parse_data = self._parse_message_with_graph(message, only_output_properties)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\rasa\\core\\processor.py\", line 664, in _parse_message_with_graph\n",
      "    results = self.graph_runner.run(\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\rasa\\engine\\runner\\dask.py\", line 101, in run\n",
      "    dask_result = dask.get(run_graph, run_targets)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\dask\\local.py\", line 552, in get_sync\n",
      "    return get_async(\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\dask\\local.py\", line 495, in get_async\n",
      "    for key, res_info, failed in queue_get(queue).result():\n",
      "  File \"c:\\users\\darsh\\appdata\\local\\programs\\python\\python38\\lib\\concurrent\\futures\\_base.py\", line 432, in result\n",
      "    return self.__get_result()\n",
      "  File \"c:\\users\\darsh\\appdata\\local\\programs\\python\\python38\\lib\\concurrent\\futures\\_base.py\", line 388, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\dask\\local.py\", line 537, in submit\n",
      "    fut.set_result(fn(*args, **kwargs))\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\dask\\local.py\", line 233, in batch_execute_tasks\n",
      "    return [execute_task(*a) for a in it]\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\dask\\local.py\", line 233, in <listcomp>\n",
      "    return [execute_task(*a) for a in it]\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\dask\\local.py\", line 224, in execute_task\n",
      "    result = pack_exception(e, dumps)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\dask\\local.py\", line 219, in execute_task\n",
      "    result = _execute_task(task, data)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\dask\\core.py\", line 119, in _execute_task\n",
      "    return func(*(_execute_task(a, cache) for a in args))\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\rasa\\engine\\graph.py\", line 464, in __call__\n",
      "    output = self._fn(self._component, **run_kwargs)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\rasa\\nlu\\featurizers\\dense_featurizer\\lm_featurizer.py\", line 740, in process\n",
      "    self._process_message(message)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\rasa\\nlu\\featurizers\\dense_featurizer\\lm_featurizer.py\", line 751, in _process_message\n",
      "    self._get_docs_for_batch(\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\rasa\\nlu\\featurizers\\dense_featurizer\\lm_featurizer.py\", line 686, in _get_docs_for_batch\n",
      "    ) = self._get_model_features_for_batch(\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\rasa\\nlu\\featurizers\\dense_featurizer\\lm_featurizer.py\", line 618, in _get_model_features_for_batch\n",
      "    sequence_hidden_states = self._compute_batch_sequence_features(\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\rasa\\nlu\\featurizers\\dense_featurizer\\lm_featurizer.py\", line 467, in _compute_batch_sequence_features\n",
      "    model_outputs = self.model(\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 1129, in call\n",
      "    outputs = self.bert(\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 870, in call\n",
      "    encoder_outputs = self.encoder(\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 543, in call\n",
      "    layer_outputs = layer_module(\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 453, in call\n",
      "    self_attention_outputs = self.attention(\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 369, in call\n",
      "    self_outputs = self.self_attention(\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 283, in call\n",
      "    value_layer = self.transpose_for_scores(self.value(inputs=hidden_states), batch_size)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 243, in transpose_for_scores\n",
      "    tensor = tf.reshape(tensor=tensor, shape=(batch_size, -1, self.num_attention_heads, self.attention_head_size))\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 1082, in op_dispatch_handler\n",
      "    return dispatch_target(*args, **kwargs)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 194, in reshape\n",
      "    result = gen_array_ops.reshape(tensor, shape, name)\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 8540, in reshape\n",
      "    return reshape_eager_fallback(\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 8565, in reshape_eager_fallback\n",
      "    _result = _execute.execute(b\"Reshape\", 1, inputs=_inputs_flat, attrs=_attrs,\n",
      "  File \"c:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 54, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n",
      "\u001b[93mc:\\Users\\darsh\\Desktop\\Chat Bot\\env\\lib\\site-packages\\rasa\\utils\\train_utils.py:528: UserWarning: constrain_similarities is set to `False`. It is recommended to set it to `True` when using cross-entropy loss.\n",
      "  rasa.shared.utils.io.raise_warning(\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "from rasa.core.agent import Agent\n",
    "\n",
    "model_name = \"diet-heavy-20\"\n",
    "\n",
    "model_path = f\"./models/{model_name}.gz\"\n",
    "nlu_agent = Agent.load(model_path=model_path)\n",
    "\n",
    "def get_prediction(query):\n",
    "    pred = asyncio.run(nlu_agent.parse_message(message_data=query))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasa.shared.nlu.training_data.loading as nlu_loading\n",
    "\n",
    "val_data = nlu_loading.load_data(\"./model_data/val_data_no_entities.yml\")\n",
    "val_data = [m.as_dict() for m in val_data.intent_examples]\n",
    "\n",
    "val_data_entity = nlu_loading.load_data(\"./model_data/val_data_entities.yml\")\n",
    "val_data_entity = [m.as_dict() for m in val_data_entity.entity_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Query\", \"Expected Entity\", \"Predicted Entity\", \"Confidence\"]\n",
    "result = pd.DataFrame([], columns=columns)\n",
    "\n",
    "for i in range(len(val_data)):\n",
    "    query = val_data[i][\"text\"]\n",
    "    pred = get_prediction(query)\n",
    "    pred = pred[\"entities\"]\n",
    "    expec = val_data_entity[i][\"entities\"]\n",
    "    token_point = {}\n",
    "    for pred_entity in pred:\n",
    "        token_point[pred_entity[\"start\"]] = {\n",
    "            \"Expected Entity\": \"\"\n",
    "        }\n",
    "        token_point[pred_entity[\"start\"]][\"Predicted Entity\"] = pred_entity[\"entity\"]\n",
    "        token_point[pred_entity[\"start\"]][\"Confidence\"] = pred_entity[\"confidence_entity\"]\n",
    "    for expec_entity in expec:\n",
    "        if expec_entity[\"start\"] not in token_point:\n",
    "            token_point[expec_entity[\"start\"]] = {\n",
    "                \"Predicted Entity\": \"\",\n",
    "                \"Confidence\": 0,\n",
    "            }\n",
    "        token_point[expec_entity[\"start\"]][\"Expected Entity\"] = expec_entity[\"entity\"]\n",
    "\n",
    "    for token in token_point.values():\n",
    "        row= {}\n",
    "        row[\"Query\"] = query\n",
    "        row[\"Expected Entity\"] = token[\"Expected Entity\"]\n",
    "        row[\"Predicted Entity\"] = token[\"Predicted Entity\"]\n",
    "        row[\"Confidence\"] = token[\"Confidence\"]\n",
    "        result = pd.concat([result, pd.DataFrame(row, index=[0])], ignore_index=True)\n",
    "\n",
    "result.to_csv(f\"./logs/entity-{model_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Query\", \"Expected Intent\", \"Predicted Intent\"]+[intent[:-5] for intent in os.listdir(\"./dataset/Train/\")]\n",
    "result = pd.DataFrame([], columns=columns)\n",
    "\n",
    "for data in val_data:\n",
    "    row = {}\n",
    "    query = data[\"text\"]\n",
    "    expected_intent = data[\"intent\"]\n",
    "    row[\"Query\"] = query\n",
    "    row[\"Expected Intent\"] = expected_intent\n",
    "    pred = get_prediction(query)\n",
    "    row[\"Predicted Intent\"] = pred[\"intent\"][\"name\"]\n",
    "    for pred_intent in pred[\"intent_ranking\"]:\n",
    "        row[pred_intent[\"name\"]] = pred_intent[\"confidence\"]\n",
    "\n",
    "    result = pd.concat([result, pd.DataFrame(row, index=[0])], ignore_index=True)\n",
    "\n",
    "result.to_csv(f\"./logs/intent-{model_name}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:37:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7259767ce7d1632178b07a04b9177bf968a9100dc4f9641ec426af43f4451571"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
